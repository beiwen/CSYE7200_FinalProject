{"paragraphs":[{"text":"%spark2\n\nspark.version","dateUpdated":"2018-04-17T22:11:31+0000","config":{"colWidth":12,"editorMode":"ace/mode/scala","results":{},"enabled":true,"editorSetting":{"language":"scala"}},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1524003048056_-795248580","id":"20180416-001216_1293330430","dateCreated":"2018-04-17T22:10:48+0000","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:4509","user":"admin","dateFinished":"2018-04-17T22:12:35+0000","dateStarted":"2018-04-17T22:11:31+0000","results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"\nres0: String = 2.1.1.2.6.1.4-2\n"}]}},{"text":"%spark2\n\n\nimport org.apache.spark.sql.types._\nimport org.apache.spark.sql.{Dataset, SparkSession}\n\nval schema: StructType = new StructType(Array(StructField(\"date\", StringType, false),\n    StructField(\"game_size\", IntegerType, false),\n    StructField(\"match_id\",StringType, false),\n    StructField(\"match_mode\", StringType, false),\n    StructField(\"party_size\", IntegerType, false),\n    StructField(\"player_assists\", IntegerType, false),\n    StructField(\"player_dbno\",IntegerType,false),\n    StructField(\"player_dist_ride\",DoubleType,false),\n    StructField(\"player_dist_walk\",DoubleType,false),\n    StructField(\"player_dmg\",IntegerType,false),\n    StructField(\"player_kills\",IntegerType,false),\n    StructField(\"player_name\",StringType,false),\n    StructField(\"player_survive_time\",DoubleType,false),\n    StructField(\"team_id\",IntegerType,false),\n    StructField(\"team_placement\",IntegerType,false))\n  )\n\ncase class Player (game_size: Int, match_id: String, match_mode: String, party_size: Int,\n                   player_assists: Int, player_dbno: Int, player_dist_ride: Double, player_dist_walk: Double,\n                   player_dmg: Int, player_kills: Int, player_name: String, player_survive_time: Double,\n                   team_id: Int, team_placement: Int)\n\nimplicit val spark = {\n    SparkSession\n      .builder()\n      .appName(\"IngestRawToDataset\")\n      .master(\"local[*]\")\n      .getOrCreate()\n  }\n  \nval path = \"s3a://csye7200.bucket.forfinal/aggregate/*\"\n\nimport spark.implicits._\ndef ingest(srcDir: String, schema: StructType)(implicit spark:SparkSession): Dataset[Player] = {\n      spark.read\n        .option(\"header\", \"true\")\n        .option(\"inferSchema\", \"false\")\n        .schema(schema)\n        .format(\"csv\")\n        .load(srcDir)\n        .as[Player]\n    }\n\nval ds = ingest(path, schema)\n  ","dateUpdated":"2018-04-17T22:12:40+0000","config":{"colWidth":12,"editorMode":"ace/mode/scala","results":{},"enabled":true,"editorSetting":{"language":"scala"}},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1524003048059_-794863831","id":"20180416-001445_30035730","dateCreated":"2018-04-17T22:10:48+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:4510","user":"admin","dateFinished":"2018-04-17T22:12:46+0000","dateStarted":"2018-04-17T22:12:40+0000","results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"\nimport org.apache.spark.sql.types._\n\nimport org.apache.spark.sql.{Dataset, SparkSession}\n\nschema: org.apache.spark.sql.types.StructType = StructType(StructField(date,StringType,false), StructField(game_size,IntegerType,false), StructField(match_id,StringType,false), StructField(match_mode,StringType,false), StructField(party_size,IntegerType,false), StructField(player_assists,IntegerType,false), StructField(player_dbno,IntegerType,false), StructField(player_dist_ride,DoubleType,false), StructField(player_dist_walk,DoubleType,false), StructField(player_dmg,IntegerType,false), StructField(player_kills,IntegerType,false), StructField(player_name,StringType,false), StructField(player_survive_time,DoubleType,false), StructField(team_id,IntegerType,false), StructField(team_placement,IntegerType,false))\n\ndefined class Player\n\nspark: org.apache.spark.sql.SparkSession = org.apache.spark.sql.SparkSession@c7837f\n\npath: String = s3a://csye7200.bucket.forfinal/aggregate/*\n\nimport spark.implicits._\n\ningest: (srcDir: String, schema: org.apache.spark.sql.types.StructType)(implicit spark: org.apache.spark.sql.SparkSession)org.apache.spark.sql.Dataset[Player]\n\nds: org.apache.spark.sql.Dataset[Player] = [date: string, game_size: int ... 13 more fields]\n"}]}},{"text":"%spark2\n\nds.cache\n\n\n","dateUpdated":"2018-04-17T22:12:52+0000","config":{"colWidth":12,"editorMode":"ace/mode/scala","results":{},"enabled":true,"editorSetting":{"language":"scala"}},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"\nres7: ds.type = [date: string, game_size: int ... 13 more fields]\n"}]},"apps":[],"jobName":"paragraph_1524003048060_-796787576","id":"20180416-002217_584507964","dateCreated":"2018-04-17T22:10:48+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:4511","user":"admin","dateFinished":"2018-04-17T22:12:52+0000","dateStarted":"2018-04-17T22:12:52+0000"},{"text":"%spark2\n\ndef filterPlayers(ds: Dataset[Player]): Dataset[Player] = {\n      ds.filter(d => (d.player_dist_ride != 0 || d.player_dist_walk != 0) && d.player_survive_time <= 2400)\n    }\n\nval filteredDS = filterPlayers(ds)\n","dateUpdated":"2018-04-17T22:10:48+0000","config":{"colWidth":12,"editorMode":"ace/mode/scala","results":{},"enabled":true,"editorSetting":{"language":"scala"}},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"\nfilterPlayers: (ds: org.apache.spark.sql.Dataset[Player])org.apache.spark.sql.Dataset[Player]\n\nfilteredDS: org.apache.spark.sql.Dataset[Player] = [date: string, game_size: int ... 13 more fields]\n"}]},"apps":[],"jobName":"paragraph_1524003048061_-797172325","id":"20180416-002448_17994666","dateCreated":"2018-04-17T22:10:48+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:4512"},{"text":"%spark2\n\nfilteredDS.cache","dateUpdated":"2018-04-17T22:10:48+0000","config":{"colWidth":12,"editorMode":"ace/mode/scala","results":{},"enabled":true,"editorSetting":{"language":"scala"}},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"\nres16: filteredDS.type = [date: string, game_size: int ... 13 more fields]\n"}]},"apps":[],"jobName":"paragraph_1524003048062_-796018078","id":"20180416-003028_320577826","dateCreated":"2018-04-17T22:10:48+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:4513"},{"text":"%spark2.spark\n\nimport org.apache.spark.sql.{DataFrame, Dataset}\nimport org.apache.spark.sql.functions._\nimport org.apache.spark.ml.feature.{StandardScaler, VectorAssembler}\n\nval inputCols1 = Array(\"player_dmg\", \"player_kills\")\n\nval soloPlayers = filteredDS.filter(d => d.party_size == 1).cache()\n\ndef dropCols(df: DataFrame): DataFrame = {\n      df.drop(\"date\",\"game_size\",\"match_id\",\"match_mode\",\"party_size\",\"player_assists\",\"player_dbno\",\"player_dist_ride\",\"player_dist_walk\",\"player_name\",\"player_survive_time\",\"team_id\")\n  }\n  \ndef createDfWithFeature(ds: Dataset[Player],inputCols: Array[String]): DataFrame = {\n    val vecAss = new VectorAssembler().setInputCols(inputCols).setOutputCol(\"unscaled_features\")\n    val assembledDf = vecAss.transform(ds)\n    val scaler = new StandardScaler().setInputCol(\"unscaled_features\").setOutputCol(\"features\")\n    val scalerModel = scaler.fit(assembledDf)\n    val scaledDf = scalerModel.transform(assembledDf)\n    dropCols(scaledDf)\n  }\nval soloDF =  createDfWithFeature(soloPlayers, inputCols1).cache","dateUpdated":"2018-04-17T22:10:48+0000","config":{"colWidth":12,"editorMode":"ace/mode/scala","results":{"0":{"graph":{"mode":"table","height":142,"optionOpen":false}}},"enabled":true,"editorSetting":{"language":"scala","editOnDblClick":false}},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1524003048063_-796402827","id":"20180416-003140_1990292219","dateCreated":"2018-04-17T22:10:48+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:4514"},{"text":"%spark2\nimport org.apache.spark.ml.clustering.{KMeans}\n\ndef determinK(assembledDf: DataFrame): IndexedSeq[(Int, Double)] = {\n    val clusters = Range(2, 10)\n    clusters zip clusters.map(k => new KMeans().setK(k).setSeed(1L).fit(assembledDf).computeCost(assembledDf))\n  }","dateUpdated":"2018-04-17T22:10:48+0000","config":{"colWidth":12,"editorMode":"ace/mode/scala","results":{},"enabled":true,"editorSetting":{"language":"scala"}},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"\nimport org.apache.spark.ml.clustering.KMeans\n\ndeterminK: (assembledDf: org.apache.spark.sql.DataFrame)IndexedSeq[(Int, Double)]\n"}]},"apps":[],"jobName":"paragraph_1524003048064_-712142818","id":"20180416-004428_1543762589","dateCreated":"2018-04-17T22:10:48+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:4515"},{"text":"%spark2\nsoloDF.show\ndeterminK(soloDF)","dateUpdated":"2018-04-17T22:10:48+0000","config":{"colWidth":12,"editorMode":"ace/mode/scala","results":{},"enabled":true,"editorSetting":{"language":"scala"}},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"+----------+------------+--------------+-----------------+--------------------+\n|player_dmg|player_kills|team_placement|unscaled_features|            features|\n+----------+------------+--------------+-----------------+--------------------+\n|         0|           0|            79|        (2,[],[])|           (2,[],[])|\n|         0|           0|            87|        (2,[],[])|           (2,[],[])|\n|       124|           0|            35|      [124.0,0.0]|[0.75713279376360...|\n|        24|           0|            46|       [24.0,0.0]|[0.14654183105101...|\n|       100|           1|            47|      [100.0,1.0]|[0.61059096271258...|\n|       438|           4|            29|      [438.0,4.0]|[2.67438841668110...|\n|         0|           0|            48|        (2,[],[])|           (2,[],[])|\n|         0|           0|            67|        (2,[],[])|           (2,[],[])|\n|         0|           0|            63|        (2,[],[])|           (2,[],[])|\n|        60|           0|            27|       [60.0,0.0]|[0.36635457762754...|\n|       114|           1|            76|      [114.0,1.0]|[0.69607369749234...|\n|         0|           0|            80|        (2,[],[])|           (2,[],[])|\n|         0|           0|            53|        (2,[],[])|           (2,[],[])|\n|       169|           1|            85|      [169.0,1.0]|[1.03189872698426...|\n|        96|           1|            21|       [96.0,1.0]|[0.58616732420407...|\n|         0|           0|            62|        (2,[],[])|           (2,[],[])|\n|         2|           0|            58|        [2.0,0.0]|[0.01221181925425...|\n|         0|           0|            72|        (2,[],[])|           (2,[],[])|\n|        67|           1|            28|       [67.0,1.0]|[0.40909594501742...|\n|       515|           6|             1|      [515.0,6.0]|[3.14454345796979...|\n+----------+------------+--------------+-----------------+--------------------+\nonly showing top 20 rows\n\n\nres52: IndexedSeq[(Int, Double)] = Vector((2,1.1610011415010758E7), (3,6661578.434835187), (4,4698076.8819699045), (5,3171568.2853164426), (6,2403580.8833517907), (7,2289728.5942950635), (8,1720659.0631163765), (9,1645556.5405718))\n"}]},"apps":[],"jobName":"paragraph_1524003048065_-712527567","id":"20180416-011827_1161538451","dateCreated":"2018-04-17T22:10:48+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:4516"},{"text":"%spark2\nval df = spark.createDataFrame(res52)\ndf.createOrReplaceTempView(\"dftemp\")","dateUpdated":"2018-04-17T22:10:48+0000","config":{"colWidth":12,"editorMode":"ace/mode/scala","results":{},"enabled":true,"editorSetting":{"language":"scala"}},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"\ndf: org.apache.spark.sql.DataFrame = [_1: int, _2: double]\n"}]},"apps":[],"jobName":"paragraph_1524003048066_-711373320","id":"20180416-011928_2035003285","dateCreated":"2018-04-17T22:10:48+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:4517"},{"text":"%spark2.sql\nSELECT _1, _2 AS cost FROM dftemp","dateUpdated":"2018-04-17T22:10:48+0000","config":{"colWidth":12,"editorMode":"ace/mode/sql","results":{"0":{"graph":{"mode":"lineChart","height":300,"optionOpen":false},"helium":{}}},"enabled":true,"editorSetting":{"language":"sql","editOnDblClick":false}},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TABLE","data":"_1\tcost\n2\t1.1610011415010758E7\n3\t6661578.434835187\n4\t4698076.8819699045\n5\t3171568.2853164426\n6\t2403580.8833517907\n7\t2289728.5942950635\n8\t1720659.0631163765\n9\t1645556.5405718\n"}]},"apps":[],"jobName":"paragraph_1524003048067_-711758069","id":"20180416-014558_1355026392","dateCreated":"2018-04-17T22:10:48+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:4518"},{"text":"%spark2\n\nimport org.apache.spark.sql.{DataFrame, Dataset}\nimport org.apache.spark.sql.functions._\nimport org.apache.spark.ml.feature.{StandardScaler, VectorAssembler}\n\nval inputCols2 = Array(\"player_assists\",\"player_dbno\",\"player_dmg\",\"player_kills\")\n\nval duoPlayers = filteredDS.filter(d => d.party_size == 2).cache()\n\ndef dropCols(df: DataFrame): DataFrame = {\n      df.drop(\"date\",\"game_size\",\"match_id\",\"match_mode\",\"party_size\",\"player_dist_ride\",\"player_dist_walk\",\"player_name\",\"player_survive_time\",\"team_id\")\n  }\n  \ndef createDfWithFeature(ds: Dataset[Player],inputCols: Array[String]): DataFrame = {\n    val vecAss = new VectorAssembler().setInputCols(inputCols).setOutputCol(\"unscaled_features\")\n    val assembledDf = vecAss.transform(ds)\n    val scaler = new StandardScaler().setInputCol(\"unscaled_features\").setOutputCol(\"features\")\n    val scalerModel = scaler.fit(assembledDf)\n    val scaledDf = scalerModel.transform(assembledDf)\n    dropCols(scaledDf)\n}\n\nval duoDF =  createDfWithFeature(duoPlayers,inputCols2).cache\n\n  ","dateUpdated":"2018-04-17T22:10:48+0000","config":{"colWidth":12,"editorMode":"ace/mode/scala","results":{},"enabled":true,"editorSetting":{"language":"scala","editOnDblClick":false}},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"\nimport org.apache.spark.sql.{DataFrame, Dataset}\n\nimport org.apache.spark.sql.functions._\n\nimport org.apache.spark.ml.feature.{StandardScaler, VectorAssembler}\n\ninputCols2: Array[String] = Array(player_assists, player_dbno, player_dmg, player_kills)\n\nduoPlayers: org.apache.spark.sql.Dataset[Player] = [date: string, game_size: int ... 13 more fields]\n\ndropCols: (df: org.apache.spark.sql.DataFrame)org.apache.spark.sql.DataFrame\n\ncreateDfWithFeature: (ds: org.apache.spark.sql.Dataset[Player], inputCols: Array[String])org.apache.spark.sql.DataFrame\n\nduoDF: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [player_assists: int, player_dbno: int ... 5 more fields]\n"}]},"apps":[],"jobName":"paragraph_1524003048068_-713681813","id":"20180416-014704_1133271422","dateCreated":"2018-04-17T22:10:48+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:4519"},{"text":"%spark2\n\nduoDF.show()","dateUpdated":"2018-04-17T22:10:48+0000","config":{"colWidth":12,"editorMode":"ace/mode/scala","results":{},"enabled":true,"editorSetting":{"language":"scala","editOnDblClick":false}},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"+--------------+-----------+----------+------------+--------------+-------------------+--------------------+\n|player_assists|player_dbno|player_dmg|player_kills|team_placement|  unscaled_features|            features|\n+--------------+-----------+----------+------------+--------------+-------------------+--------------------+\n|             0|          1|       117|           1|            18|[0.0,1.0,117.0,1.0]|[0.0,1.0443813462...|\n|             0|          1|       127|           1|            18|[0.0,1.0,127.0,1.0]|[0.0,1.0443813462...|\n|             0|          0|        67|           0|            33|     (4,[2],[67.0])|(4,[2],[0.3970951...|\n|             0|          0|         0|           0|            33|          (4,[],[])|           (4,[],[])|\n|             0|          0|       175|           2|            11|[0.0,0.0,175.0,2.0]|[0.0,0.0,1.037188...|\n|             0|          0|        65|           0|            11|     (4,[2],[65.0])|(4,[2],[0.3852415...|\n|             0|          0|         0|           0|            17|          (4,[],[])|           (4,[],[])|\n|             0|          0|         0|           0|            17|          (4,[],[])|           (4,[],[])|\n|             0|          0|        79|           0|            24|     (4,[2],[79.0])|(4,[2],[0.4682166...|\n|             0|          1|       101|           1|            24|[0.0,1.0,101.0,1.0]|[0.0,1.0443813462...|\n|             0|          1|        54|           1|             4| [0.0,1.0,54.0,1.0]|[0.0,1.0443813462...|\n|             0|          0|        34|           0|             4|     (4,[2],[34.0])|(4,[2],[0.2015109...|\n|             0|          0|         0|           0|            34|          (4,[],[])|           (4,[],[])|\n|             0|          1|       215|           2|            34|[0.0,1.0,215.0,2.0]|[0.0,1.0443813462...|\n|             0|          0|        75|           1|             2| [0.0,0.0,75.0,1.0]|[0.0,0.0,0.444509...|\n|             0|          0|        84|           1|             2| [0.0,0.0,84.0,1.0]|[0.0,0.0,0.497850...|\n|             0|          0|         0|           0|             3|          (4,[],[])|           (4,[],[])|\n|             0|          4|       673|           6|             3|[0.0,4.0,673.0,6.0]|[0.0,4.1775253850...|\n|             0|          0|       117|           1|            20|[0.0,0.0,117.0,1.0]|[0.0,0.0,0.693434...|\n|             0|          1|       100|           1|            20|[0.0,1.0,100.0,1.0]|[0.0,1.0443813462...|\n+--------------+-----------+----------+------------+--------------+-------------------+--------------------+\nonly showing top 20 rows\n\n"}]},"apps":[],"jobName":"paragraph_1524003048069_-714066562","id":"20180416-015413_375030594","dateCreated":"2018-04-17T22:10:48+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:4520"},{"text":"%spark2\n\ndeterminK(duoDF)\n","dateUpdated":"2018-04-17T22:10:48+0000","config":{"colWidth":12,"editorMode":"ace/mode/scala","results":{},"enabled":true,"editorSetting":{"language":"scala"}},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"\nres66: IndexedSeq[(Int, Double)] = Vector((2,4.843552457366613E7), (3,3.7122557942747444E7), (4,2.7345370045455534E7), (5,2.2269152715427298E7), (6,1.9000878661728013E7), (7,1.703927929960851E7), (8,1.6453545741106689E7), (9,1.4375924427421333E7))\n"}]},"apps":[],"jobName":"paragraph_1524003048070_-712912315","id":"20180416-015754_29847844","dateCreated":"2018-04-17T22:10:48+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:4521"},{"text":"%spark2\n\nval df = spark.createDataFrame(res66)\ndf.createOrReplaceTempView(\"duoDFtemp\")\n","dateUpdated":"2018-04-17T22:10:48+0000","config":{"colWidth":12,"editorMode":"ace/mode/scala","results":{},"enabled":true,"editorSetting":{"language":"scala"}},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"\ndf: org.apache.spark.sql.DataFrame = [_1: int, _2: double]\n"}]},"apps":[],"jobName":"paragraph_1524003048070_-712912315","id":"20180416-020659_1241334071","dateCreated":"2018-04-17T22:10:48+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:4522"},{"text":"%spark2.sql\nSELECT _1, _2 AS cost FROM duoDFtemp\nSELECT _1, _2 AS cost FROM duoDFtemp\n","dateUpdated":"2018-04-17T22:10:48+0000","config":{"colWidth":12,"editorMode":"ace/mode/sql","results":{"0":{"graph":{"mode":"lineChart","height":300,"optionOpen":false},"helium":{}}},"enabled":true,"editorSetting":{"language":"sql","editOnDblClick":false}},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TABLE","data":"_1\tcost\n2\t4.843552457366613E7\n3\t3.7122557942747444E7\n4\t2.7345370045455534E7\n5\t2.2269152715427298E7\n6\t1.9000878661728013E7\n7\t1.703927929960851E7\n8\t1.6453545741106689E7\n9\t1.4375924427421333E7\n"}]},"apps":[],"jobName":"paragraph_1524003048071_-713297064","id":"20180416-040649_351157073","dateCreated":"2018-04-17T22:10:48+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:4523"},{"text":"%spark2\n\nimport org.apache.spark.sql.{DataFrame, Dataset}\nimport org.apache.spark.sql.functions._\nimport org.apache.spark.ml.feature.{StandardScaler, VectorAssembler}\n\nval inputCols2 = Array(\"player_assists\",\"player_dbno\",\"player_dmg\",\"player_kills\")\nval squadPlayers = filteredDS.filter(d => d.party_size == 4).cache()\n\ndef dropCols(df: DataFrame): DataFrame = {\n      df.drop(\"date\",\"game_size\",\"match_id\",\"match_mode\",\"party_size\",\"player_dist_ride\",\"player_dist_walk\",\"player_name\",\"player_survive_time\",\"team_id\")\n  }\n  \ndef createDfWithFeature(ds: Dataset[Player],inputCols: Array[String]): DataFrame = {\n    val vecAss = new VectorAssembler().setInputCols(inputCols).setOutputCol(\"unscaled_features\")\n    val assembledDf = vecAss.transform(ds)\n    val scaler = new StandardScaler().setInputCol(\"unscaled_features\").setOutputCol(\"features\")\n    val scalerModel = scaler.fit(assembledDf)\n    val scaledDf = scalerModel.transform(assembledDf)\n    dropCols(scaledDf)\n}\n\nval squadDF =  createDfWithFeature(squadPlayers,inputCols2).cache","dateUpdated":"2018-04-17T22:10:48+0000","config":{"colWidth":12,"editorMode":"ace/mode/scala","results":{},"enabled":true,"editorSetting":{"language":"scala"}},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"\nimport org.apache.spark.sql.{DataFrame, Dataset}\n\nimport org.apache.spark.sql.functions._\n\nimport org.apache.spark.ml.feature.{StandardScaler, VectorAssembler}\n\ninputCols2: Array[String] = Array(player_assists, player_dbno, player_dmg, player_kills)\n\nsquadPlayers: org.apache.spark.sql.Dataset[Player] = [date: string, game_size: int ... 13 more fields]\n\ndropCols: (df: org.apache.spark.sql.DataFrame)org.apache.spark.sql.DataFrame\n\ncreateDfWithFeature: (ds: org.apache.spark.sql.Dataset[Player], inputCols: Array[String])org.apache.spark.sql.DataFrame\n\nsquadDF: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [player_assists: int, player_dbno: int ... 5 more fields]\n"}]},"apps":[],"jobName":"paragraph_1524003048071_-713297064","id":"20180416-040710_653052732","dateCreated":"2018-04-17T22:10:48+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:4524"},{"text":"%spark2\n\nsquadDF.show()","dateUpdated":"2018-04-17T22:10:48+0000","config":{"colWidth":12,"editorMode":"ace/mode/scala","results":{},"enabled":true,"editorSetting":{"language":"scala"}},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"+--------------+-----------+----------+------------+--------------+--------------------+--------------------+\n|player_assists|player_dbno|player_dmg|player_kills|team_placement|   unscaled_features|            features|\n+--------------+-----------+----------+------------+--------------+--------------------+--------------------+\n|             3|          6|      1116|           9|             1|[3.0,6.0,1116.0,9.0]|[4.42520352058715...|\n|             1|          7|      1059|           9|             1|[1.0,7.0,1059.0,9.0]|[1.47506784019571...|\n|             3|          0|       201|           0|             1| [3.0,0.0,201.0,0.0]|[4.42520352058715...|\n|             1|          0|        54|           0|            10|  [1.0,0.0,54.0,0.0]|[1.47506784019571...|\n|             0|          2|       178|           2|            10| [0.0,2.0,178.0,2.0]|[0.0,1.4704042893...|\n|             0|          0|         0|           0|            10|           (4,[],[])|           (4,[],[])|\n|             0|          1|        71|           2|            10|  [0.0,1.0,71.0,2.0]|[0.0,0.7352021446...|\n|             1|          0|        37|           0|            24|  [1.0,0.0,37.0,0.0]|[1.47506784019571...|\n|             0|          1|       122|           1|            24| [0.0,1.0,122.0,1.0]|[0.0,0.7352021446...|\n|             0|          0|         9|           0|            24|       (4,[2],[9.0])|(4,[2],[0.0516898...|\n|             1|          4|       430|           3|             7| [1.0,4.0,430.0,3.0]|[1.47506784019571...|\n|             0|          0|         0|           0|             7|           (4,[],[])|           (4,[],[])|\n|             1|          0|        33|           1|             7|  [1.0,0.0,33.0,1.0]|[1.47506784019571...|\n|             2|          0|        95|           0|             7|  [2.0,0.0,95.0,0.0]|[2.95013568039143...|\n|             0|          2|       519|           6|            15| [0.0,2.0,519.0,6.0]|[0.0,1.4704042893...|\n|             1|          3|       316|           2|            15| [1.0,3.0,316.0,2.0]|[1.47506784019571...|\n|             0|          0|         0|           0|            15|           (4,[],[])|           (4,[],[])|\n|             0|          1|       125|           1|            15| [0.0,1.0,125.0,1.0]|[0.0,0.7352021446...|\n|             0|          1|       128|           1|            18| [0.0,1.0,128.0,1.0]|[0.0,0.7352021446...|\n|             0|          0|        48|           0|            18|      (4,[2],[48.0])|(4,[2],[0.2756790...|\n+--------------+-----------+----------+------------+--------------+--------------------+--------------------+\nonly showing top 20 rows\n\n"}]},"apps":[],"jobName":"paragraph_1524003048072_-715220809","id":"20180416-041312_1583342685","dateCreated":"2018-04-17T22:10:48+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:4525"},{"text":"%spark2\n\nimport org.apache.spark.ml.clustering.{KMeans}\n\ndef determinK(assembledDf: DataFrame): IndexedSeq[(Int, Double)] = {\n    val clusters = Range(3, 10)\n    clusters zip clusters.map(k => new KMeans().setK(k).setSeed(1L).fit(assembledDf).computeCost(assembledDf))\n  }","dateUpdated":"2018-04-17T22:10:48+0000","config":{"colWidth":12,"editorMode":"ace/mode/scala","results":{},"enabled":true,"editorSetting":{"language":"scala"}},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"\nimport org.apache.spark.ml.clustering.KMeans\n\ndeterminK: (assembledDf: org.apache.spark.sql.DataFrame)IndexedSeq[(Int, Double)]\n"}]},"apps":[],"jobName":"paragraph_1524003048073_-715605558","id":"20180416-041449_1632202627","dateCreated":"2018-04-17T22:10:48+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:4526"},{"text":"%spark2\ndeterminK(squadDF)","dateUpdated":"2018-04-17T22:10:48+0000","config":{"colWidth":12,"editorMode":"ace/mode/scala","results":{},"enabled":true,"editorSetting":{"language":"scala"}},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"\nres80: IndexedSeq[(Int, Double)] = Vector((3,5.368090893571634E7), (4,4.1129305954688296E7), (5,3.500036827332842E7), (6,3.087705778019726E7), (7,2.8220038739338435E7), (8,2.3396522107052907E7), (9,2.162405549115112E7))\n"}]},"apps":[],"jobName":"paragraph_1524003048073_-715605558","id":"20180416-041542_719036888","dateCreated":"2018-04-17T22:10:48+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:4527"},{"text":"%spark2\nval df = spark.createDataFrame(res80)\ndf.createOrReplaceTempView(\"squadDFtemp\")","dateUpdated":"2018-04-17T22:10:48+0000","config":{"colWidth":12,"editorMode":"ace/mode/scala","results":{},"enabled":true,"editorSetting":{"language":"scala"}},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"\ndf: org.apache.spark.sql.DataFrame = [_1: int, _2: double]\n"}]},"apps":[],"jobName":"paragraph_1524003048074_-714451311","id":"20180416-042439_882290996","dateCreated":"2018-04-17T22:10:48+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:4528"},{"text":"%spark2.sql\nSELECT _1, _2 AS cost FROM squadDFtemp\n","dateUpdated":"2018-04-17T22:10:48+0000","config":{"colWidth":12,"editorMode":"ace/mode/sql","results":{"0":{"graph":{"mode":"lineChart","height":300,"optionOpen":false},"helium":{}}},"enabled":true,"editorSetting":{"language":"sql","editOnDblClick":false}},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TABLE","data":"_1\tcost\n3\t5.368090893571634E7\n4\t4.1129305954688296E7\n5\t3.500036827332842E7\n6\t3.087705778019726E7\n7\t2.8220038739338435E7\n8\t2.3396522107052907E7\n9\t2.162405549115112E7\n"}]},"apps":[],"jobName":"paragraph_1524003048074_-714451311","id":"20180416-065247_880193005","dateCreated":"2018-04-17T22:10:48+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:4529"},{"text":"%spark2\n\nimport org.apache.spark.ml.clustering.{KMeans, KMeansModel}\nimport org.apache.spark.sql.{DataFrame, Dataset}\nimport org.apache.spark.sql.functions._\nimport org.apache.spark.ml.feature.{StandardScaler, VectorAssembler}\n\nval inputCols1 = Array(\"player_dmg\",\"player_kills\")\nval inputCols2 = Array(\"player_assists\",\"player_dbno\",\"player_dmg\",\"player_kills\")\n\ndef filterPlayers(ds: Dataset[Player]): Dataset[Player] = {\n      ds.filter(d => (d.player_dist_ride != 0 || d.player_dist_walk != 0) && d.player_survive_time <= 2400)\n    }\n\n  \ndef dropCols(df: DataFrame): DataFrame = {\n    val party_size = df.select(\"party_size\").take(1).map(_(0)).toList.head\n    if(party_size == 1) {\n      df.drop(\"date\",\"game_size\",\"match_id\",\"match_mode\",\"party_size\",\"player_assists\",\"player_dbno\",\"player_dist_ride\",\"player_dist_walk\",\"player_name\",\"player_survive_time\",\"team_id\")\n    } else{\n      df.drop(\"date\",\"game_size\",\"match_id\",\"match_mode\",\"party_size\",\"player_dist_ride\",\"player_dist_walk\",\"player_name\",\"player_survive_time\",\"team_id\")\n    }\n  }\n    \ndef createDfWithFeature(ds: Dataset[Player],inputCols: Array[String]): DataFrame = {\n    val vecAss = new VectorAssembler().setInputCols(inputCols).setOutputCol(\"unscaled_features\")\n    val assembledDf = vecAss.transform(ds)\n    val scaler = new StandardScaler().setInputCol(\"unscaled_features\").setOutputCol(\"features\")\n    val scalerModel = scaler.fit(assembledDf)\n    val scaledDf = scalerModel.transform(assembledDf)\n    dropCols(scaledDf)\n  }\n    \ndef clusteringHelper(dsSeprated: Dataset[Player]): KMeansModel = {\n    val k = dsSeprated.head().party_size match {\n      case 1 => 5\n      case 2 => 5\n      case 4 => 4\n      case _ => 0\n    }\n    val kmeans = new KMeans().setK(k).setSeed(1L)\n    if(dsSeprated.head.party_size == 1) {\n      val fitDf = createDfWithFeature(dsSeprated,inputCols1)\n      fitDf.cache()\n      kmeans.fit(fitDf)\n    }else {\n      val fitDf = createDfWithFeature(dsSeprated,inputCols2)\n      fitDf.cache()\n      kmeans.fit(fitDf)\n    }\n}\n\ndef clustering(ds: Dataset[Player]) : Array[KMeansModel] = {\n    val filteredDS = filterPlayers(ds)\n    val soloPlayers = filteredDS.filter(d => d.party_size == 1).cache()\n    val duoPlayers = filteredDS.filter(d => d.party_size == 2).cache()\n    val squadPlayers = filteredDS.filter(d => d.party_size == 4).cache()\n    Array(soloPlayers, duoPlayers, squadPlayers).map(pd => clusteringHelper(pd))\n  }\n  \n val models = clustering(ds)\n\n","dateUpdated":"2018-04-17T22:24:56+0000","config":{"colWidth":12,"editorMode":"ace/mode/scala","results":{},"enabled":true,"editorSetting":{"language":"scala","editOnDblClick":false}},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1524003048075_-714836060","id":"20180416-065321_1957896061","dateCreated":"2018-04-17T22:10:48+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:4530","user":"admin","dateFinished":"2018-04-17T22:44:47+0000","dateStarted":"2018-04-17T22:24:56+0000","results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"\nimport org.apache.spark.ml.clustering.{KMeans, KMeansModel}\n\nimport org.apache.spark.sql.{DataFrame, Dataset}\n\nimport org.apache.spark.sql.functions._\n\nimport org.apache.spark.ml.feature.{StandardScaler, VectorAssembler}\n\ninputCols1: Array[String] = Array(player_dmg, player_kills)\n\ninputCols2: Array[String] = Array(player_assists, player_dbno, player_dmg, player_kills)\n\nfilterPlayers: (ds: org.apache.spark.sql.Dataset[Player])org.apache.spark.sql.Dataset[Player]\n\ndropCols: (df: org.apache.spark.sql.DataFrame)org.apache.spark.sql.DataFrame\n\ncreateDfWithFeature: (ds: org.apache.spark.sql.Dataset[Player], inputCols: Array[String])org.apache.spark.sql.DataFrame\n\nclusteringHelper: (dsSeprated: org.apache.spark.sql.Dataset[Player])org.apache.spark.ml.clustering.KMeansModel\n\nclustering: (ds: org.apache.spark.sql.Dataset[Player])Array[org.apache.spark.ml.clustering.KMeansModel]\n\nmodels: Array[org.apache.spark.ml.clustering.KMeansModel] = Array(kmeans_7dd341b6628a, kmeans_a935a7298dd5, kmeans_9f5b56946a9d)\n"}]}},{"text":"%spark2\n\nmodels(0).save(\"s3a://csye7200.bucket.forfinal/Models/ClusteringByBattleForSolo\")\nmodels(1).save(\"s3a://csye7200.bucket.forfinal/Models/ClusteringByBattleForDuo\")\nmodels(2).save(\"s3a://csye7200.bucket.forfinal/Models/ClusteringByBattleForSquad\")","user":"admin","dateUpdated":"2018-04-18T03:50:29+0000","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1524003428259_-298200618","id":"20180417-221708_783881311","dateCreated":"2018-04-17T22:17:08+0000","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:6446","dateFinished":"2018-04-18T03:50:48+0000","dateStarted":"2018-04-18T03:50:29+0000","results":{"code":"SUCCESS","msg":[]}},{"text":"%spark2\n","user":"admin","dateUpdated":"2018-04-18T03:49:29+0000","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"scala"},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1524023369067_-1258959055","id":"20180418-034929_346367408","dateCreated":"2018-04-18T03:49:29+0000","status":"READY","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:6845"}],"name":"clusteringByBattle","id":"2DCQUFGDE","angularObjects":{"2DBAJ88WP:shared_process":[],"2DE72RY4R:shared_process":[],"2DC2GTUSD:shared_process":[],"2DD7CVM96:shared_process":[],"2DD5R1E1V:shared_process":[],"2C4U48MY3_spark2:shared_process":[],"2DCB7ZMCJ:shared_process":[]},"config":{"looknfeel":"default","personalizedMode":"false"},"info":{}}